<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://waistcoat-buffalo.github.io/</id><title>Karma's Blog</title><subtitle>papers, blogs, methodology, notes, psychology, mind, karmastring</subtitle> <updated>2021-02-22T00:26:49-05:00</updated> <author> <name>Karma String</name> <uri>https://waistcoat-buffalo.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://waistcoat-buffalo.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en-US" href="https://waistcoat-buffalo.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator> <rights> © 2021 Karma String </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>CVPR18 - End-to-end Recovery of Human Shape and Pose</title><link href="https://waistcoat-buffalo.github.io/posts/paper_E2ERecovery/" rel="alternate" type="text/html" title="CVPR18 - End-to-end Recovery of Human Shape and Pose" /><published>2021-02-16T17:45:00-05:00</published> <updated>2021-02-16T17:45:00-05:00</updated> <id>https://waistcoat-buffalo.github.io/posts/paper_E2ERecovery/</id> <content src="https://waistcoat-buffalo.github.io/posts/paper_E2ERecovery/" /> <author> <name>Karma String</name> </author> <category term="Research" /> <summary> 概述 这篇paper”End-to-end Recovery of Human Shape and Pose“是在CVPR2018上发表的。在给出图片中人的Bounding box后， 这篇paper里的方法可以real-time地从2D image中重构出人的3D Mesh。 目标 从单张的2D RGB图像中重构出图像中人的3D mesh。作者提出的model可以使用2D-to-3D的supervision进行训练，也可以不使用任何paired 2D-to-3D supervision来进行weakly-supervised training。 面临的问题 作者列出了三个challenges： 缺少3D的对应数据。The lack of large-scale ground truth 3D annotation for in-the-wild images. ... </summary> </entry> <entry><title>TED Notes</title><link href="https://waistcoat-buffalo.github.io/posts/note_TED/" rel="alternate" type="text/html" title="TED Notes" /><published>2021-02-05T20:00:00-05:00</published> <updated>2021-02-05T20:00:00-05:00</updated> <id>https://waistcoat-buffalo.github.io/posts/note_TED/</id> <content src="https://waistcoat-buffalo.github.io/posts/note_TED/" /> <author> <name>Karma String</name> </author> <category term="Mind" /> <summary> 概述 这篇博客主要用来持续地记录观看TED见到的一些思想、启发和表达。熟悉程度如下： 泛:泛听 精:精听 写:听写 总:总结观点 背:背诵 完:结束 v3 [泛]: Do you really know why you do what you do v2 [泛]: How to make hard choices v1 [写]: The paradox of choice 本文的主要观点是： 虽然更多的选择给人们带来了freedom和welfare，但也给人带来了paralyzation和不幸福。演讲者给出的解决方案是lower your expectation。 本文的逻辑结构是： </summary> </entry> <entry><title>ICCV19 - Skeleton-Aware 3D Human Shape Reconstruction From Point Clouds</title><link href="https://waistcoat-buffalo.github.io/posts/paper_SAShape/" rel="alternate" type="text/html" title="ICCV19 - Skeleton-Aware 3D Human Shape Reconstruction From Point Clouds" /><published>2021-02-04T16:15:00-05:00</published> <updated>2021-02-04T16:15:00-05:00</updated> <id>https://waistcoat-buffalo.github.io/posts/paper_SAShape/</id> <content src="https://waistcoat-buffalo.github.io/posts/paper_SAShape/" /> <author> <name>Karma String</name> </author> <category term="Research" /> <summary> 概述 这篇paper”Skeleton-Aware 3D Human Shape Reconstruction From Point Clouds“是在ICCV2019上发表的。根据作者的叙述，这可能是第一篇用点云数据并辅以SMPL Model来做3D human reconstruction的文章。以下用SAShape来指代这篇paper。 目标 用3D Point Cloud数据生成人的3D Shape （在具体实现中，作者先在synthesized dataset上做了supervised training，再于unseen dataset上做unsupervised fine-tuning） 主要贡献： Skeleton awareness，即在直接的point feature到SMPL parameter的映射中间，加了一层skeleton joint fea... </summary> </entry> <entry><title>CVPR20 - VIBE: Video Inference for Human Body Pose and Shape Estimation</title><link href="https://waistcoat-buffalo.github.io/posts/paper_VIBE/" rel="alternate" type="text/html" title="CVPR20 - VIBE: Video Inference for Human Body Pose and Shape Estimation" /><published>2020-10-05T15:15:00-04:00</published> <updated>2020-10-05T15:15:00-04:00</updated> <id>https://waistcoat-buffalo.github.io/posts/paper_VIBE/</id> <content src="https://waistcoat-buffalo.github.io/posts/paper_VIBE/" /> <author> <name>Karma String</name> </author> <category term="Research" /> <summary> 概述 这篇paper”VIBE: Video Inference for Human Body Pose and Shape Estimation“是由Max Planck Institute（MPI）的人在CVPR2020上发表的，并提供了code和pretrained model。以下用VIBE来指代这篇paper。 目标 用monocular video数据生成人的3D motion的Pose和Shape 主要贡献： 使用了AMASS dataset对model进行了adversarial training。（这个方法其实已经是老生常谈的了，只是这种类似AMASS的3D motion capture dataset不常有。这个AMASS dataset看上去也主要是由MPI的人做的。） 在discriminator中使用了attention mechanism... </summary> </entry> <entry><title>Hello World!</title><link href="https://waistcoat-buffalo.github.io/posts/hello/" rel="alternate" type="text/html" title="Hello World!" /><published>2020-09-30T22:45:00-04:00</published> <updated>2020-09-30T22:45:00-04:00</updated> <id>https://waistcoat-buffalo.github.io/posts/hello/</id> <content src="https://waistcoat-buffalo.github.io/posts/hello/" /> <author> <name>Karma String</name> </author> <category term="Manual" /> <summary> 概述 2020年9月30日的今天，我开始了这个blog来尝试记录一些见到的经验和知识。 这些经验和知识包括以下几个方面： 读一些Research Paper的记录。 我会基于对这个paper的整体评价、对我当前research比较有用的值得关注的点以及一些有价值的细节进行记录。当然这个部分也是这个blog诞生的主要意义。 读一些书籍的记录。 这些会被记录书籍一般包括以下几类：关于思维方式的，关于方法论的，关于心理学的，关于历史的。 对于一些经典的计算方法的记录。 这些经典计算方法，不仅包含计算机领域的算法，还可能包括诸如数学、物理学等自然科学的某些经典计算方法。 少量个人对算法... </summary> </entry> </feed>
